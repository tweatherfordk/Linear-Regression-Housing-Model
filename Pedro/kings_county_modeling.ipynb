{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'find_stack_level' from 'pandas.util._exceptions' (C:\\Users\\pedro\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\util\\_exceptions.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-9ff1a1b97a9c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m   \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLinearRegression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig_init\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m from pandas.core.api import (\n\u001B[0m\u001B[0;32m     52\u001B[0m     \u001B[1;31m# dtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mInt8Dtype\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\api.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0misnull\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnotna\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnotnull\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malgorithms\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfactorize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue_counts\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marrays\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mCategorical\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mboolean\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mBooleanDtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\algorithms.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstruction\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mextract_array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindexers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mvalidate_indices\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mTYPE_CHECKING\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexers\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m from pandas.core.indexers.utils import (\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mcheck_array_indexer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mcheck_key_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mcheck_setitem_lengths\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mdeprecate_ndim_indexing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexers\\utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mArrayLike\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m )\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_exceptions\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfind_stack_level\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m from pandas.core.dtypes.common import (\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'find_stack_level' from 'pandas.util._exceptions' (C:\\Users\\pedro\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\util\\_exceptions.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from   sklearn.linear_model import LinearRegression\n",
    "from   sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "king = pd.read_excel(\"..\\data\\king_county_home_sales.xlsx\", index_col= \"Unnamed: 0\" )\n",
    "king.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "king.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "king[[]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here is a first attempt at a simple linear regression model using the sqft_living room of a home to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# price as a function of sqfr_living room, this is just a pedigocial tool and will serve as a basis\n",
    "\n",
    "\n",
    "X, y = king[['sqft_living']] , king[['price']]\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "# Init, fit, score\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {model.score(X_train, y_train)}\")\n",
    "\n",
    "print(f\"Test score: {model.score(X, y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot fit\n",
    "plt.scatter(king.sqft_living, king.price, alpha=0.3)\n",
    "plt.plot(king.sqft_living, model.predict(king[['sqft_living']]), c='darkorange')\n",
    "plt.title(\"Squarefoot Living Room ~ Price\")\n",
    "plt.xlabel(\"Squart Footage\")\n",
    "plt.ylabel(\"Sales Price\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now it is time for a multi linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "king.columns # calling all columns in order to determine what subset of columns we will use for our models\n",
    "features = king[['bedrooms', 'bathrooms', 'sqft_living',\n",
    "                 'sqft_lot', 'floors', 'waterfront', 'sqft_above',\n",
    "                 'sqft_basement', 'lat', 'long', 'sqft_living15',\n",
    "                 'sqft_lot15', 'view_ord', 'condition_ord', 'grade_ord', 'age', \"renovated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mulit model time: (all ~ price) decided to use every column here except for yr_built since this column and age are redundant and zipcode since it is an arbitraruy number not relevant to our dataframe yet.\n",
    "\n",
    "X, y = features, king[['price']]\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Init, fit, score\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {multi_model.score(X_train, y_train)}\")\n",
    "multi_model_score = multi_model.score(X_test, y_test)\n",
    "print(f\"Test score: {multi_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An r^2 score of 0.68 isn't bad but it isn't great either. Maybe we have some collinearity issues going on and we need to be more selective about our features. So its time to do some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def identify_correlated(df, threshold):\n",
    "    \"\"\"\n",
    "    A function to identify highly correlated features.\n",
    "    \"\"\"\n",
    "    # Compute correlation matrix with absolute values\n",
    "    matrix = df.corr().abs()\n",
    "\n",
    "    # Create a boolean mask\n",
    "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "\n",
    "    # Subset the matrix\n",
    "    reduced_matrix = matrix.mask(mask)\n",
    "\n",
    "    # Find cols that meet the threshold\n",
    "    to_drop = [c for c in reduced_matrix.columns if \\\n",
    "              any(reduced_matrix[c] > threshold)]\n",
    "\n",
    "    return to_drop\n",
    "\n",
    "# Thanks to this towards data science for this function: https://towardsdatascience.com/how-to-use-pairwise-correlation-for-robust-feature-selection-20a60ef7d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = identify_correlated(king, .7) #proceeding with dropping these features that are highly correlated\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build feature/target arrays\n",
    "X, y = king[['bedrooms','sqft_lot', 'floors', 'waterfront',\n",
    "             'sqft_basement', 'sqft_living15',\n",
    "             'sqft_lot15', 'view_ord', 'condition_ord', 'grade_ord', 'age', \"renovated\"]] , king[['price']]\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Init, fit, score\n",
    "multi_model_red = LinearRegression()\n",
    "multi_model_red.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {multi_model_red.score(X_train, y_train)}\")\n",
    "multi_model_score_red = multi_model_red.score(X_test, y_test)\n",
    "print(f\"Test score: {multi_model_red.score(X_test, y_test)}\")\n",
    "\n",
    "print(f\"\\nOur r^2 score was {multi_model_score:.04f} and our new reduced score is {multi_model_score_red:.04f} this is a large decrease in r^2 after removing features that are collinear, so lets go back to our original model with all the features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So how should we proceed from here? One step is to calculate the interactions between different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "king.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = king['price']\n",
    "X = king[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront',\n",
    "          'sqft_above', 'sqft_basement','lat', 'long', 'zipcode',\n",
    "          'sqft_living15', 'sqft_lot15', 'renovated', 'view_ord', 'condition_ord', 'grade_ord', 'age']]\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "linear_withinteraction = PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False)\n",
    "\n",
    "X_transformed = linear_withinteraction.fit_transform(X.drop(columns= 'zipcode')) #removing zipcode column this will become evident latter when we dummy our zip code\n",
    "\n",
    "feat_names = pd.Series(linear_withinteraction.get_feature_names())\n",
    "\n",
    "feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xs = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',  'x11', 'x12', 'x13', 'x14', 'x15','x16']\n",
    "\n",
    "columns = X.columns\n",
    "\n",
    "map_dict = {x:y for x,y in zip(xs, columns)}\n",
    "\n",
    "for key, value in map_dict.items():\n",
    "    feat_names = feat_names.str.replace(key, value)\n",
    "\n",
    "\n",
    "X_trans_df = pd.DataFrame(X_transformed)\n",
    "X_trans_df.columns = feat_names\n",
    "\n",
    "X_trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_trans_standard = X_trans_df.apply(lambda x: (x - x.mean())/x.std() )\n",
    "# y_standard = (y - y.mean())/y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_trans_df, y, test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Init, fit, score\n",
    "stand_model = LinearRegression()\n",
    "stand_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {stand_model.score(X_train, y_train)}\")\n",
    "\n",
    "print(f\"Testing score: {stand_model.score(X_test, y_test)}\")\n",
    "\n",
    "stand_model_score  = stand_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now one last model except now with zip code as a dummied feature instead of as an integer value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummy_zip = pd.get_dummies(king['zipcode'], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One more model with all of our features alongside dummied zip code data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "king.columns # calling all columns in order to determine what subset of columns we will use for our models\n",
    "features = king[['bedrooms', 'bathrooms', 'sqft_living',\n",
    "                 'sqft_lot', 'floors', 'waterfront', 'sqft_above',\n",
    "                 'sqft_basement', 'sqft_living15', 'lat', 'long',\n",
    "                 'sqft_lot15', 'view_ord', 'condition_ord', 'grade_ord', 'age', \"renovated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = features.join(dummy_zip)\n",
    "\n",
    "X, y = features, king[['price']]\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Init, fit, score\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {multi_model.score(X_train, y_train)}\")\n",
    "multi_model_score = multi_model.score(X_test, y_test)\n",
    "print(f\"Test score: {multi_model.score(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "learn-env",
   "language": "python",
   "display_name": "Python (learn-env)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}