{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This file will be used for some explinitory data analysis of the kings county data. This data set was provided to students of the flat iron school in order to implement a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from itertools  import tee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\data\\kc_house_data.csv\")\n",
    "df.head() # inspecting our dataframe and seeing our columns and some basic values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that 'waterfront' and 'yr_renovated' appear to be the only columns with null values, however we shall further inspect these columns and see if this is in fact the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info() # notice that 'waterfront' and 'yr_renovated' and \"view\" appear to be the only columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"date\", \"yr_built\", \"yr_renovated\", \"waterfront\", \"view\", \"condition\", \"grade\", \"sqft_basement\"]] # a subset of our dataframe with only\n",
    "# the columns that need cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"]) #changing date column from string to datetime format\n",
    "\n",
    "df[\"date\"].min(), df[\"date\"].max() #notice our dataset only includes data from one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.yr_renovated.fillna(0.0, inplace= True) # replacing NaN values with 0.0 in yr_renovated column\n",
    "\n",
    "df.yr_renovated.isna().sum() # checking to see if there are any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"sqft_basement\"].replace(to_replace= \"?\", value = 0.0, inplace= True ) # replacing ? with 0.0 in our sqft_basement column\n",
    "\n",
    "df[\"sqft_basement\"] = df[\"sqft_basement\"].astype(\"float\") #converting sqft_basement to type float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.waterfront.fillna(\"NO\", inplace= True) #filling in NaN values with NO for waterfront\n",
    "\n",
    "df.waterfront = df.waterfront.eq('YES').mul(1) # now converting YES and NO to 1 and 0 respectively, this will help with our model fitting later\n",
    "\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.view.unique() # inspecting view column to see if there are any NaN values\n",
    "\n",
    "df.view.fillna(\"NONE\", inplace = True) #filling in NaN values with string NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now it is time to move away from filling in our null values and correcting our data types and to begin dealing with our ordinal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"renovated\"] = df[\"yr_renovated\"].apply(lambda x: 0 if x==0.0 else 1) # adding a new column where 1 means home was renovated and 0 is never renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.yr_renovated.fillna(df['yr_built'], inplace= True) # replacing NaN values with corresponding yr_built value\n",
    "# in yr_renovated column\n",
    "df.yr_renovated.isna().sum() # checking to see if there are any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"grade\"] = df.grade.apply(lambda x: (int(x[0:2]))) # adding a grade numeric column which is derived from the grade column.\n",
    "# Only using the integer grading (3-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ord_cat_selector = ['view', 'condition', 'grade'] # these three columns all have ordinal data and must be dealt with accordingly\n",
    "\n",
    "cat_subset = df[ord_cat_selector] # a subset of our dataframe with only ordinal data\n",
    "\n",
    "cat_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_subset['view'].unique() #inspecting the columns and arranging the values accordingly\n",
    "cat_subset['condition'].unique()\n",
    "cat_subset['grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "view_list = ['NONE', 'FAIR', 'AVERAGE', 'GOOD', 'EXCELLENT'] # order for each column (least to greatest)\n",
    "condition_list = ['Poor', 'Fair', 'Average', 'Good', 'Very Good']\n",
    "grade_list = [3,4,5,6,7,8,9,10,11,12,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "o_enc = OrdinalEncoder(categories = [view_list, condition_list, grade_list])\n",
    "o_enc.fit(cat_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_subset = pd.DataFrame(o_enc.transform(cat_subset), columns = cat_subset.columns) # create a new ordinal encoded dataframe\n",
    "\n",
    "#Merge with our original dataframe\n",
    "transformed_df =df.join(X_subset, rsuffix= \"_ord\")\n",
    "\n",
    "# dropping columns redundant columns that were used to derive ordinal columns\n",
    "transformed_df.drop(columns = [\"view\", \"condition\", \"grade\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df[\"age\"] = 2015 - transformed_df[\"yr_built\"] # adding an age column that gives us the total age of the home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Noticed an outlier in our dataframe and decided to manually edit it, using online airbnb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.loc[transformed_df.bedrooms == transformed_df.bedrooms.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df['bedrooms'][15856] = 3 # setting the correct number of bedrooms for this entry, found via zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.loc[transformed_df.bedrooms == transformed_df.bedrooms.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = transformed_df[['lat', 'long']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to add a special feature to our dataframe, distance to seattle downtown from your home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pairwise function implemented to iterate through two consecutive rows (pairs) in a data frame\n",
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#empty list - will be used to store calculated distances\n",
    "list = [0]\n",
    "\n",
    "# Loop through each row in the data frame using pairwise\n",
    "for (i1, row1), (i2, row2) in pairwise(lat_long.iterrows()):\n",
    "    #Assign latitude and longitude as origin/departure points\n",
    "    LatOrigin = row1['lat']\n",
    "    LongOrigin = row1['long']\n",
    "    point = (LatOrigin, LongOrigin)\n",
    "    list.append(point)\n",
    "#Add column 'Distance' to data frame and assign to list values\n",
    "transformed_df['point'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df['point'][0] = (47.5112, -122.257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "downtown_seattle = (47.6050, -122.3344)\n",
    "\n",
    "import geopy.distance\n",
    "\n",
    "transformed_df['distance_to_downtown_seattle_miles'] = transformed_df['point'].apply(lambda point: geopy.distance.geodesic(downtown_seattle, point).miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformed_df['distance_to_downtown_seattle_miles'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_hq = (47.622620, -122.336739)\n",
    "\n",
    "import geopy.distance\n",
    "\n",
    "transformed_df['distance_to_amazon_hq'] = transformed_df['point'].apply(lambda point: geopy.distance.geodesic(amazon_hq, point).miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two different ways to visalize the same thing: our desired predicted variable y and the line that best fits for each of our features. This will give us a good understadning of which features we should use to train our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting a heatmap for the correlation of each column to each other\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "sns.heatmap(transformed_df.corr(), center = 0, cmap = \"coolwarm\", annot=True, linewidths=.5, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desired_columns = ['bedrooms', 'bathrooms', 'sqft_living',\n",
    "'sqft_lot', 'floors', 'waterfront', 'sqft_above', 'sqft_basement',\n",
    "'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'view_ord',\n",
    "'distance_to_downtown_seattle_miles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for col in desired_columns:\n",
    "    sns.lmplot(data=transformed_df, x = col,  y=\"price\", fit_reg =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#transformed_df.to_excel(\"king_county_home_sales.xlsx\") #only run this line if this is your first time running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finaly we are ready to move onto the model fitting portion of our project. Notice that this is just a preliminary EDA with only the data that was provided for us. However, after doing some basic linear regression models with this data we will return to this phase and try to fit additional data. For example, all our of home sales data is from the year 2014 to 2015 specifically from the kings county region. In order to better anlysis the price of a home in this region we should try to find more recent data, such as data from 2020-2022. Also, in order to better estimate the price of a home, we would like to calculate data such as distance to the nearest park, walking score, distance to public transit, neighborhood score, and demographic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
